{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 第10章: 事前学習済み言語モデル（GPT型）"
      ],
      "metadata": {
        "id": "kr7Z_an-gIFd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 90. 次単語予測"
      ],
      "metadata": {
        "id": "g-OaV13HgLMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, set_seed\n",
        "from pprint import pprint\n",
        "\n",
        "text = \"The movie was full of\"\n",
        "generator = pipeline('text-generation', model='gpt2')\n",
        "set_seed(42)\n",
        "output = generator(text, max_length=10, num_return_sequences=10)\n",
        "pprint(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rn6nyNI0gK5L",
        "outputId": "69a29b3e-0d9f-4d35-a0d0-0c750df62bfe"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': 'The movie was full of dark humor that was really'},\n",
            " {'generated_text': 'The movie was full of big, huge black holes'},\n",
            " {'generated_text': 'The movie was full of hilarious scenes involving clowns'},\n",
            " {'generated_text': 'The movie was full of weird and silly twists,'},\n",
            " {'generated_text': 'The movie was full of references to the events of'},\n",
            " {'generated_text': 'The movie was full of \"I can\\'t believe'},\n",
            " {'generated_text': 'The movie was full of laughs, but it was'},\n",
            " {'generated_text': 'The movie was full of weird, silly jokes,'},\n",
            " {'generated_text': 'The movie was full of \"horrible people\"'},\n",
            " {'generated_text': 'The movie was full of nudity, though, and'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 91. 続きのテキストの予測"
      ],
      "metadata": {
        "id": "yBdyjVqSgM3k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URf1Fbg_e3ZV"
      },
      "outputs": [],
      "source": [
        "meta-llama/Llama-3.2-1B-Instruct"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 92. 予測されたテキストの確率を計算"
      ],
      "metadata": {
        "id": "gdWY_WN4gOJM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mAK6MaX_gPue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 93. パープレキシティ"
      ],
      "metadata": {
        "id": "na9dvEJUgP9c"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SI614KWcgRLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 94. チャットテンプレート"
      ],
      "metadata": {
        "id": "FtTn1lpFgRYb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DQQV-4OIgSbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 95. マルチターンのチャット"
      ],
      "metadata": {
        "id": "cKr1YHw1gSnP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fsLXc3Y2gTt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 96. プロンプトによる感情分析"
      ],
      "metadata": {
        "id": "aTU_FE7FgT2x"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kau4qtt7gU8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 97. 埋め込みに基づく感情分析"
      ],
      "metadata": {
        "id": "ca6DMpLWgWAv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LCDrDp0AgXbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 98. ファインチューニング"
      ],
      "metadata": {
        "id": "ZSIf41cMgX6i"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GYLN8VTcgZH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 99. 選好チューニング"
      ],
      "metadata": {
        "id": "gdGNChqpgZVA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L0U1XT20gacr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}